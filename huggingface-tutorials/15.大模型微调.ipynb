{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ğŸ¤— PEFTåŠ è½½é€‚é…å™¨\n",
    "\n",
    "å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•åœ¨å¾®è°ƒæœŸé—´å†»ç»“é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œå¹¶åœ¨å…¶é¡¶éƒ¨æ·»åŠ å°‘é‡å¯è®­ç»ƒå‚æ•°ï¼ˆé€‚é…å™¨ï¼‰ã€‚é€‚é…å™¨ç»è¿‡è®­ç»ƒä»¥å­¦ä¹ ç‰¹å®šä»»åŠ¡çš„ä¿¡æ¯ã€‚è¿™ç§æ–¹æ³•å·²è¢«è¯æ˜åœ¨äº§ç”Ÿä¸å®Œå…¨å¾®è°ƒæ¨¡å‹å¯æ¯”çš„ç»“æœçš„åŒæ—¶ï¼Œå…·æœ‰éå¸¸é«˜æ•ˆçš„å†…å­˜ä½¿ç”¨å’Œè¾ƒä½çš„è®¡ç®—ä½¿ç”¨ã€‚\n",
    "\n",
    "ä½¿ç”¨PEFTè®­ç»ƒçš„é€‚é…å™¨é€šå¸¸æ¯”å®Œæ•´æ¨¡å‹å°ä¸€ä¸ªæ•°é‡çº§ï¼Œè¿™ä½¿å¾—å…±äº«ã€å­˜å‚¨å’ŒåŠ è½½å®ƒä»¬å˜å¾—æ›´åŠ æ–¹ä¾¿ã€‚\n",
    "\n",
    "![](https://image.rarelimiting.com/PEFT-hub-screenshot.png)\n",
    "\n",
    "\n",
    "â€œå­˜å‚¨åœ¨Hubä¸Šçš„OPTForCausalLMæ¨¡å‹çš„é€‚é…å™¨æƒé‡ä»…çº¦6MBï¼Œè€Œå®Œæ•´æ¨¡å‹æƒé‡çš„å¤§å°å¯èƒ½çº¦ä¸º700MBã€‚â€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®¾ç½®\n",
    "\n",
    "å¼€å§‹å®‰è£…ğŸ¤— PEFTï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install peft\n",
    "```\n",
    "\n",
    "\n",
    "å¦‚æœæ‚¨æƒ³å°è¯•å…¨æ–°çš„åŠŸèƒ½ï¼Œæ‚¨å¯èƒ½ä¼šå¯¹ä»æºä»£ç å®‰è£…è¯¥åº“æ„Ÿå…´è¶£ï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/huggingface/peft.git\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ”¯æŒçš„PEFTæ¨¡å‹\n",
    "\n",
    "ğŸ¤— TransformersåŸç”Ÿæ”¯æŒä¸€äº›PEFTæ–¹æ³•ï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥åŠ è½½å­˜å‚¨åœ¨æœ¬åœ°æˆ–Hubä¸Šçš„é€‚é…å™¨æƒé‡ï¼Œå¹¶ä½¿ç”¨å‡ è¡Œä»£ç è½»æ¾è¿è¡Œæˆ–è®­ç»ƒå®ƒä»¬ã€‚æ”¯æŒä»¥ä¸‹æ–¹æ³•ï¼š\n",
    "\n",
    "- ä½ç§©é€‚é…å™¨ï¼ˆLow Rank Adaptersï¼‰\n",
    "- IA3\n",
    "- AdaLoRA\n",
    "\n",
    "å¦‚æœæ‚¨æƒ³ä½¿ç”¨å…¶ä»–PEFTæ–¹æ³•ï¼Œå¦‚æç¤ºå­¦ä¹ æˆ–æç¤ºè°ƒæ•´ï¼Œæˆ–è€…äº†è§£ğŸ¤— PEFTåº“çš„ä¸€èˆ¬ä¿¡æ¯ï¼Œè¯·å‚é˜…æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŠ è½½PEFTé€‚é…å™¨\n",
    "\n",
    "è¦ä»ğŸ¤— TransformersåŠ è½½å’Œä½¿ç”¨PEFTé€‚é…å™¨æ¨¡å‹ï¼Œè¯·ç¡®ä¿Hubå­˜å‚¨åº“æˆ–æœ¬åœ°ç›®å½•åŒ…å«ä¸€ä¸ªadapter_config.jsonæ–‡ä»¶å’Œé€‚é…å™¨æƒé‡ï¼Œå¦‚ä¸Šé¢çš„ç¤ºä¾‹å›¾æ‰€ç¤ºã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨AutoModelForç±»åŠ è½½PEFTé€‚é…å™¨æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œè¦åŠ è½½ç”¨äºå› æœè¯­è¨€å»ºæ¨¡çš„PEFTé€‚é…å™¨æ¨¡å‹ï¼š\n",
    "\n",
    "- æŒ‡å®šPEFTæ¨¡å‹id\n",
    "- å°†å…¶ä¼ é€’ç»™AutoModelForCausalLMç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"ybelkada/opt-350m-lora\"\n",
    "model = AutoModelForCausalLM.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‚¨å¯ä»¥ä½¿ç”¨AutoModelForç±»æˆ–åŸºæœ¬æ¨¡å‹ç±»ï¼ˆå¦‚OPTForCausalLMæˆ–LlamaForCausalLMï¼‰åŠ è½½PEFTé€‚é…å™¨ã€‚\n",
    "\n",
    "æ‚¨è¿˜å¯ä»¥é€šè¿‡è°ƒç”¨load_adapteræ–¹æ³•åŠ è½½PEFTé€‚é…å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"facebook/opt-350m\"\n",
    "peft_model_id = \"ybelkada/opt-350m-lora\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "model.load_adapter(peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŠ è½½8ä½æˆ–4ä½ç²¾åº¦\n",
    "\n",
    "bitsandbytesé›†æˆæ”¯æŒ8ä½å’Œ4ä½ç²¾åº¦æ•°æ®ç±»å‹ï¼Œè¿™å¯¹äºåŠ è½½å¤§å‹æ¨¡å‹éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒå¯ä»¥èŠ‚çœå†…å­˜ï¼ˆè¯·å‚é˜…bitsandbytesé›†æˆæŒ‡å—ä»¥äº†è§£æ›´å¤šä¿¡æ¯ï¼‰ã€‚å°†load_in_8bitæˆ–load_in_4bitå‚æ•°æ·»åŠ åˆ°from_pretrained()ä¸­ï¼Œå¹¶è®¾ç½®device_map=\"auto\"ä»¥æœ‰æ•ˆåœ°å°†æ¨¡å‹åˆ†é…åˆ°æ‚¨çš„ç¡¬ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"ybelkada/opt-350m-lora\"\n",
    "model = AutoModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ·»åŠ æ–°é€‚é…å™¨\n",
    "\n",
    "åªè¦æ–°é€‚é…å™¨ä¸å½“å‰é€‚é…å™¨çš„ç±»å‹ç›¸åŒï¼Œæ‚¨å¯ä»¥ä½¿ç”¨~peft.PeftModel.add_adapterå‘å…·æœ‰ç°æœ‰é€‚é…å™¨çš„æ¨¡å‹æ·»åŠ æ–°é€‚é…å™¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨å·²å°†ç°æœ‰çš„LoRAé€‚é…å™¨é™„åŠ åˆ°æ¨¡å‹ä¸Šï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig\n",
    "\n",
    "model_id = \"facebook/opt-350m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    target_modules=[\"q_proj\", \"k_proj\"],\n",
    "    init_lora_weights=False\n",
    ")\n",
    "\n",
    "model.add_adapter(lora_config, adapter_name=\"adapter_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¦æ·»åŠ ä¸€ä¸ªæ–°çš„é€‚é…å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach new adapter with same config\n",
    "model.add_adapter(lora_config, adapter_name=\"adapter_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨~peft.PeftModel.set_adapteræ¥è®¾ç½®è¦ä½¿ç”¨çš„é€‚é…å™¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use adapter_1\n",
    "model.set_adapter(\"adapter_1\")\n",
    "output = model.generate(**inputs)\n",
    "print(tokenizer.decode(output_disabled[0], skip_special_tokens=True))\n",
    "\n",
    "# use adapter_2\n",
    "model.set_adapter(\"adapter_2\")\n",
    "output_enabled = model.generate(**inputs)\n",
    "print(tokenizer.decode(output_enabled[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¯ç”¨å’Œç¦ç”¨é€‚é…å™¨\n",
    "\n",
    "ä¸€æ—¦æ‚¨å‘æ¨¡å‹æ·»åŠ äº†é€‚é…å™¨ï¼Œæ‚¨å¯ä»¥å¯ç”¨æˆ–ç¦ç”¨é€‚é…å™¨æ¨¡å—ã€‚è¦å¯ç”¨é€‚é…å™¨æ¨¡å—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\n",
    "from peft import PeftConfig\n",
    "\n",
    "model_id = \"facebook/opt-350m\"\n",
    "adapter_model_id = \"ybelkada/opt-350m-lora\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "text = \"Hello\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "peft_config = PeftConfig.from_pretrained(adapter_model_id)\n",
    "\n",
    "# to initiate with random weights\n",
    "peft_config.init_lora_weights = False\n",
    "\n",
    "model.add_adapter(peft_config)\n",
    "model.enable_adapters()\n",
    "output = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¦ç¦ç”¨é€‚é…å™¨æ¨¡å—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.disable_adapters()\n",
    "output = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®­ç»ƒä¸€ä¸ªPEFTé€‚é…å™¨\n",
    "\n",
    "PEFTé€‚é…å™¨å—Trainerç±»æ”¯æŒï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥ä¸ºç‰¹å®šç”¨ä¾‹è®­ç»ƒä¸€ä¸ªé€‚é…å™¨ã€‚åªéœ€è¦æ·»åŠ å‡ è¡Œä»£ç ã€‚ä¾‹å¦‚ï¼Œè¦è®­ç»ƒä¸€ä¸ªLoRAé€‚é…å™¨ï¼š\n",
    "\n",
    "> å¦‚æœæ‚¨å¯¹ä½¿ç”¨Trainerå¾®è°ƒæ¨¡å‹ä¸ç†Ÿæ‚‰ï¼Œè¯·æŸ¥çœ‹å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹æ•™ç¨‹ã€‚\n",
    "\n",
    "1. ä½¿ç”¨ä»»åŠ¡ç±»å‹å’Œè¶…å‚æ•°å®šä¹‰æ‚¨çš„é€‚é…å™¨é…ç½®ï¼ˆæœ‰å…³è¶…å‚æ•°çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…~peft.LoraConfigï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. å°†é€‚é…å™¨æ·»åŠ åˆ°æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter(peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ç°åœ¨æ‚¨å¯ä»¥å°†æ¨¡å‹ä¼ é€’ç»™Trainerï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, ...)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¦ä¿å­˜æ‚¨è®­ç»ƒçš„é€‚é…å™¨å¹¶åŠ è½½å›æ¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‘PEFTé€‚é…å™¨æ·»åŠ é¢å¤–å¯è®­ç»ƒå±‚\n",
    "\n",
    "æ‚¨è¿˜å¯ä»¥é€šè¿‡åœ¨PEFTé…ç½®ä¸­ä¼ é€’modules_to_saveæ¥åœ¨å·²é™„åŠ é€‚é…å™¨çš„æ¨¡å‹é¡¶éƒ¨å¾®è°ƒé¢å¤–çš„å¯è®­ç»ƒé€‚é…å™¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³åœ¨å…·æœ‰LoRAé€‚é…å™¨çš„æ¨¡å‹é¡¶éƒ¨å¾®è°ƒlm_headï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig\n",
    "\n",
    "model_id = \"facebook/opt-350m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    target_modules=[\"q_proj\", \"k_proj\"],\n",
    "    modules_to_save=[\"lm_head\"],\n",
    ")\n",
    "\n",
    "model.add_adapter(lora_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
