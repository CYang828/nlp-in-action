{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨è„šæœ¬è¿›è¡Œè®­ç»ƒ\n",
    "\n",
    "é™¤äº†ğŸ¤— Transformersç¬”è®°æœ¬å¤–ï¼Œè¿˜æœ‰ç¤ºä¾‹è„šæœ¬ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨PyTorchã€TensorFlowæˆ–JAX/Flaxä¸ºä»»åŠ¡è®­ç»ƒæ¨¡å‹ã€‚\n",
    "\n",
    "æ‚¨è¿˜å°†æ‰¾åˆ°æˆ‘ä»¬åœ¨ç ”ç©¶é¡¹ç›®å’Œé—ç•™ç¤ºä¾‹ä¸­ä½¿ç”¨çš„è„šæœ¬ï¼Œè¿™äº›ç¤ºä¾‹å¤§å¤šæ˜¯ç”±ç¤¾åŒºè´¡çŒ®çš„ã€‚è¿™äº›è„šæœ¬æ²¡æœ‰å¾—åˆ°ç§¯æç»´æŠ¤ï¼Œå¹¶ä¸”éœ€è¦ä¸€ä¸ªç‰¹å®šç‰ˆæœ¬çš„ğŸ¤— Transformersï¼Œè¿™å¾ˆå¯èƒ½ä¸åº“çš„æœ€æ–°ç‰ˆæœ¬ä¸å…¼å®¹ã€‚\n",
    "\n",
    "ä¸åº”æœŸæœ›ç¤ºä¾‹è„šæœ¬å¯ä»¥ç›´æ¥åœ¨æ¯ä¸ªé—®é¢˜ä¸Šè¿è¡Œï¼Œå¹¶ä¸”æ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨è¦è§£å†³çš„é—®é¢˜è°ƒæ•´è„šæœ¬ã€‚ä¸ºäº†å¸®åŠ©æ‚¨è§£å†³é—®é¢˜ï¼Œå¤§å¤šæ•°è„šæœ¬å®Œå…¨æš´éœ²äº†æ•°æ®çš„é¢„å¤„ç†æ–¹å¼ï¼Œå…è®¸æ‚¨æ ¹æ®éœ€è¦è¿›è¡Œç¼–è¾‘ä»¥é€‚åº”æ‚¨çš„ç”¨ä¾‹ã€‚\n",
    "\n",
    "å¯¹äºæ‚¨æƒ³è¦åœ¨ç¤ºä¾‹è„šæœ¬ä¸­å®ç°çš„ä»»ä½•åŠŸèƒ½ï¼Œè¯·åœ¨æäº¤Pull Requestä¹‹å‰åœ¨è®ºå›æˆ–é—®é¢˜ä¸­è®¨è®ºã€‚è™½ç„¶æˆ‘ä»¬æ¬¢è¿é”™è¯¯ä¿®å¤ï¼Œä½†æˆ‘ä»¬ä¸å¤ªå¯èƒ½åˆå¹¶ä»¥ç‰ºç‰²å¯è¯»æ€§ä¸ºä»£ä»·æ·»åŠ æ›´å¤šåŠŸèƒ½çš„Pull Requestã€‚\n",
    "\n",
    "æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åœ¨PyTorchå’ŒTensorFlowä¸­è¿è¡Œä¸€ä¸ªç¤ºä¾‹æ‘˜è¦è®­ç»ƒè„šæœ¬ã€‚é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰ç¤ºä¾‹éƒ½é¢„è®¡å¯ä»¥åœ¨ä¸¤ä¸ªæ¡†æ¶ä¸­è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®¾ç½®\n",
    "è¦æˆåŠŸè¿è¡Œæœ€æ–°ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼Œæ‚¨å¿…é¡»åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­ä»æºä»£ç å®‰è£…ğŸ¤— Transformersï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/huggingface/transformers\n",
    "cd transformers\n",
    "pip install .\n",
    "```\n",
    "\n",
    "\n",
    "å¯¹äºæ—§ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼Œè¯·å•å‡»ä¸‹é¢çš„åˆ‡æ¢æŒ‰é’®ï¼š\n",
    "\n",
    "ç„¶åå°†æ‚¨å½“å‰çš„ğŸ¤— Transformerså…‹éš†åˆ‡æ¢åˆ°ç‰¹å®šç‰ˆæœ¬ï¼Œä¾‹å¦‚v3.5.1ï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "git checkout tags/v3.5.1\n",
    "```\n",
    "\n",
    "\n",
    "è®¾ç½®æ­£ç¡®çš„åº“ç‰ˆæœ¬åï¼Œè½¬åˆ°æ‚¨é€‰æ‹©çš„ç¤ºä¾‹æ–‡ä»¶å¤¹å¹¶å®‰è£…ç¤ºä¾‹ç‰¹å®šè¦æ±‚ï¼š\n",
    "\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¿è¡Œè„šæœ¬\n",
    "\n",
    "ç¤ºä¾‹è„šæœ¬ä»ğŸ¤— Datasetsåº“ä¸‹è½½å¹¶é¢„å¤„ç†æ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬ä½¿ç”¨Kerasåœ¨æ”¯æŒæ‘˜è¦çš„æ¶æ„ä¸Šå¾®è°ƒæ•°æ®é›†ã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨CNN/DailyMailæ•°æ®é›†ä¸Šå¾®è°ƒT5-smallã€‚ç”±äºT5æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼Œè¯¥æ¨¡å‹éœ€è¦é¢å¤–çš„source_prefixå‚æ•°ã€‚è¿™ä¸ªæç¤ºè®©T5çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚\n",
    "\n",
    "\n",
    "```bash\n",
    "python examples/tensorflow/summarization/run_summarization.py  \\\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --output_dir /tmp/tst-summarization  \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --do_train \\\n",
    "    --do_eval\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦\n",
    "\n",
    "Traineræ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦ï¼Œè¿™æ„å‘³ç€æ‚¨ä¹Ÿå¯ä»¥åœ¨è„šæœ¬ä¸­ä½¿ç”¨å®ƒã€‚è¦å¯ç”¨è¿™ä¸¤ä¸ªåŠŸèƒ½ï¼š\n",
    "\n",
    "- æ·»åŠ fp16å‚æ•°ä»¥å¯ç”¨æ··åˆç²¾åº¦ã€‚\n",
    "- ä½¿ç”¨nproc_per_nodeå‚æ•°è®¾ç½®è¦ä½¿ç”¨çš„GPUæ•°é‡ã€‚\n",
    "\n",
    "\n",
    "```bash\n",
    "torchrun \\\n",
    "    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\\n",
    "    --fp16 \\\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --predict_with_generate\n",
    "```\n",
    "\n",
    "\n",
    "TensorFlowè„šæœ¬åˆ©ç”¨MirroredStrategyè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ‚¨æ— éœ€å‘è®­ç»ƒè„šæœ¬æ·»åŠ ä»»ä½•é¢å¤–çš„å‚æ•°ã€‚å¦‚æœå¯ç”¨ï¼Œé»˜è®¤æƒ…å†µä¸‹TensorFlowè„šæœ¬å°†ä½¿ç”¨å¤šä¸ªGPUã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨TPUä¸Šè¿è¡Œè„šæœ¬\n",
    "\n",
    "Tensor Processing Units (TPUs)ä¸“é—¨è®¾è®¡ç”¨äºåŠ é€Ÿæ€§èƒ½ã€‚TensorFlowè„šæœ¬åˆ©ç”¨TPUStrategyåœ¨TPUä¸Šè¿›è¡Œè®­ç»ƒã€‚è¦ä½¿ç”¨TPUï¼Œè¯·å°†TPUèµ„æºçš„åç§°ä¼ é€’ç»™tpuå‚æ•°ã€‚\n",
    "\n",
    "\n",
    "```bash\n",
    "python run_summarization.py  \\\n",
    "    --tpu name_of_tpu_resource \\\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --output_dir /tmp/tst-summarization  \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --do_train \\\n",
    "    --do_eval\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a script with ğŸ¤— Accelerate\n",
    "\n",
    "## ä½¿ç”¨ğŸ¤— Accelerateè¿è¡Œè„šæœ¬\n",
    "\n",
    "ğŸ¤— Accelerateæ˜¯ä¸€ä¸ªä»…é€‚ç”¨äºPyTorchçš„åº“ï¼Œå®ƒæä¾›äº†ä¸€ç§ç»Ÿä¸€çš„æ–¹æ³•ï¼Œåœ¨å¤šç§è®¾ç½®ï¼ˆä»…CPUã€å¤šä¸ªGPUã€TPUï¼‰ä¸Šè®­ç»ƒæ¨¡å‹ï¼ŒåŒæ—¶å®Œå…¨äº†è§£PyTorchè®­ç»ƒå¾ªç¯ã€‚å¦‚æœæ‚¨å°šæœªå®‰è£…ğŸ¤— Accelerateï¼Œè¯·ç¡®ä¿å®‰è£…å®ƒï¼š\n",
    "\n",
    ">\"æ³¨æ„ï¼šç”±äºAccelerateæ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œå¿…é¡»å®‰è£…åŠ é€Ÿè„šæœ¬çš„gitç‰ˆæœ¬æ‰èƒ½è¿è¡Œè„šæœ¬\"\n",
    "```bash\n",
    "pip install git+https://github.com/huggingface/accelerate\n",
    "```\n",
    "\n",
    "\n",
    "è€Œä¸æ˜¯ä½¿ç”¨run_summarization.pyè„šæœ¬ï¼Œæ‚¨éœ€è¦ä½¿ç”¨run_summarization_no_trainer.pyè„šæœ¬ã€‚ğŸ¤— Accelerateæ”¯æŒçš„è„šæœ¬å°†åœ¨æ–‡ä»¶å¤¹ä¸­å…·æœ‰task_no_trainer.pyæ–‡ä»¶ã€‚é¦–å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åˆ›å»ºå¹¶ä¿å­˜é…ç½®æ–‡ä»¶ï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "accelerate config\n",
    "```\n",
    "\n",
    "æµ‹è¯•æ‚¨çš„è®¾ç½®ä»¥ç¡®ä¿é…ç½®æ­£ç¡®ï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "accelerate test\n",
    "```\n",
    "\n",
    "\n",
    "ç°åœ¨æ‚¨å·²ç»å‡†å¤‡å¥½å¯åŠ¨è®­ç»ƒï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "accelerate launch run_summarization_no_trainer.py \\\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --output_dir ~/tmp/tst-summarization\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a custom dataset\n",
    "\n",
    "\n",
    "The summarization script supports custom datasets as long as they are a CSV or JSON Line file. When you use your own dataset, you need to specify several additional arguments:\n",
    "\n",
    "- train_file and validation_file specify the path to your training and validation files.\n",
    "- text_column is the input text to summarize.\n",
    "- summary_column is the target text to output.\n",
    "A summarization script using a custom dataset would look like this:\n",
    "\n",
    "```bash\n",
    "python examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --train_file path_to_csv_or_jsonlines_file \\\n",
    "    --validation_file path_to_csv_or_jsonlines_file \\\n",
    "    --text_column text_column_name \\\n",
    "    --summary_column summary_column_name \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --overwrite_output_dir \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --predict_with_generate\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æµ‹è¯•è„šæœ¬\n",
    "\n",
    "åœ¨æ‰¿è¯ºè¦å®Œæˆå¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶çš„æ•´ä¸ªæ•°æ®é›†ä¹‹å‰ï¼Œé€šå¸¸æœ€å¥½åœ¨è¾ƒå°‘çš„æ•°æ®é›†ç¤ºä¾‹ä¸Šè¿è¡Œæ‚¨çš„è„šæœ¬ï¼Œä»¥ç¡®ä¿ä¸€åˆ‡æŒ‰é¢„æœŸå·¥ä½œã€‚ä½¿ç”¨ä»¥ä¸‹å‚æ•°å°†æ•°æ®é›†æˆªæ–­ä¸ºæœ€å¤§æ ·æœ¬æ•°ï¼š\n",
    "\n",
    "- max_train_samples\n",
    "- max_eval_samples\n",
    "- max_predict_samples\n",
    "\n",
    "\n",
    "```bash\n",
    "python examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --max_train_samples 50 \\\n",
    "    --max_eval_samples 50 \\\n",
    "    --max_predict_samples 50 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --predict_with_generate\n",
    "```\n",
    "\n",
    "\n",
    "å¹¶éæ‰€æœ‰ç¤ºä¾‹è„šæœ¬éƒ½æ”¯æŒmax_predict_sampleså‚æ•°ã€‚å¦‚æœä¸ç¡®å®šæ‚¨çš„è„šæœ¬æ˜¯å¦æ”¯æŒæ­¤å‚æ•°ï¼Œè¯·æ·»åŠ -hå‚æ•°è¿›è¡Œæ£€æŸ¥ï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "examples/pytorch/summarization/run_summarization.py -h\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ\n",
    "\n",
    "å¦ä¸€ä¸ªæœ‰ç”¨çš„é€‰é¡¹æ˜¯ä»å…ˆå‰çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚è¿™å°†ç¡®ä¿æ‚¨å¯ä»¥åœ¨ä¸­æ–­è®­ç»ƒåä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­ï¼Œè€Œä¸å¿…é‡æ–°å¼€å§‹ã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚\n",
    "\n",
    "ç¬¬ä¸€ç§æ–¹æ³•ä½¿ç”¨output_dir previous_output_dirå‚æ•°ä»å­˜å‚¨åœ¨output_dirä¸­çš„æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥åˆ é™¤overwrite_output_dirï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "python examples/pytorch/summarization/run_summarization.py\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --output_dir previous_output_dir \\\n",
    "    --predict_with_generate\n",
    "```\n",
    "\n",
    "\n",
    "ç¬¬äºŒç§æ–¹æ³•ä½¿ç”¨resume_from_checkpoint path_to_specific_checkpointå‚æ•°ä»ç‰¹å®šæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹æ¢å¤è®­ç»ƒã€‚\n",
    "\n",
    "\n",
    "```bash\n",
    "python examples/pytorch/summarization/run_summarization.py\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --resume_from_checkpoint path_to_specific_checkpoint \\\n",
    "    --predict_with_generate\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†äº«æ‚¨çš„æ¨¡å‹\n",
    "\n",
    "æ‰€æœ‰è„šæœ¬éƒ½å¯ä»¥å°†æ‚¨çš„æœ€ç»ˆæ¨¡å‹ä¸Šä¼ åˆ°æ¨¡å‹ä¸­å¿ƒï¼ˆModel Hubï¼‰ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ç™»å½•åˆ°Hugging Faceï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "huggingface-cli login\n",
    "```\n",
    "\n",
    "\n",
    "ç„¶ååœ¨è„šæœ¬ä¸­æ·»åŠ push_to_hubå‚æ•°ã€‚æ­¤å‚æ•°å°†åˆ›å»ºä¸€ä¸ªå…·æœ‰æ‚¨çš„Hugging Faceç”¨æˆ·åå’Œoutput_dirä¸­æŒ‡å®šçš„æ–‡ä»¶å¤¹åç§°çš„å­˜å‚¨åº“ã€‚\n",
    "\n",
    "è¦ä¸ºæ‚¨çš„å­˜å‚¨åº“æŒ‡å®šç‰¹å®šåç§°ï¼Œè¯·ä½¿ç”¨push_to_hub_model_idå‚æ•°è¿›è¡Œæ·»åŠ ã€‚è¯¥å­˜å‚¨åº“å°†è‡ªåŠ¨åˆ—åœ¨æ‚¨çš„å‘½åç©ºé—´ä¸‹ã€‚\n",
    "\n",
    "ä»¥ä¸‹ç¤ºä¾‹æ˜¾ç¤ºäº†å¦‚ä½•ä½¿ç”¨ç‰¹å®šå­˜å‚¨åº“åç§°ä¸Šä¼ æ¨¡å‹ï¼š\n",
    "\n",
    "\n",
    "```bash\n",
    "python examples/pytorch/summarization/run_summarization.py\n",
    "    --model_name_or_path google-t5/t5-small \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --dataset_name cnn_dailymail \\\n",
    "    --dataset_config \"3.0.0\" \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --push_to_hub \\\n",
    "    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --predict_with_generate\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
