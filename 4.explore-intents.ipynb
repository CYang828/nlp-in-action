{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 探索意图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用聚类探索意图\n",
    "\n",
    "在这本笔记本中，我采用了前一本笔记本中经过预处理和标记的数据，并试图通过使用有意义的文档嵌入方法（这样我的模型就可以读取数据）和无监督学习方法（如K-Means、DBScan和LDA）为数据集中的每条推文分配标签。\n",
    "\n",
    "我把我的意图分为几类，总共有11类。对于在看不见的数据上进行意图分类的成功NN训练，我认为每个意图1000个是有用的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 1.4.3\n",
      "Numpy: 1.23.2\n",
      "gensim: 4.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8z/_m3tlbk55sv4j8cl6sp2_7gw0000gn/T/ipykernel_38811/3873072998.py:50: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm().pandas()  # Enable tracking of execution progress\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017807960510253906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 32,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66fb219e9284fcb9e100da5a189a916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010404825210571289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 32,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 77175,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77d387b29e64f559c36549cf20850ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     [new, update, i️, make, sure, download, yester...\n",
       "6     [hey, anyone, else, upgraded, io, issue, capit...\n",
       "12    [hello, internet, someone, explain, symbol, ke...\n",
       "13    [get, screenshot, say, iphonex, reserve, email...\n",
       "15    [thank, update, phone, even, slow, barely, wor...\n",
       "Name: inbound_text, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need more packages!\n",
    "# Data science\n",
    "import pandas as pd\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "import numpy as np\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "\n",
    "# Unsupervised Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Word Embeddings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import gensim\n",
    "print(f'gensim: {gensim.__version__}')\n",
    "\n",
    "# Doc2Vec\n",
    "from nltk.tokenize import word_tokenize \n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "# Storing as objects via serialization\n",
    "from tempfile import mkdtemp\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Directory\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Cool progress bars\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()  # Enable tracking of execution progress\n",
    "\n",
    "# Reading in intents\n",
    "with open(r'objects/intents.yml') as file:\n",
    "    intents = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "# Loading in the already saved processed dataset\n",
    "processed_inbound = pd.read_pickle('objects/processed_inbound.pkl')\n",
    "\n",
    "# Representing my tokenized data as String documents and storing it into a variable\n",
    "string_processed_inbound = processed_inbound.progress_apply(\" \".join)\n",
    "\n",
    "# We start with this data, here's the preview\n",
    "processed_inbound.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Collection With Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to represent a document as a vector is with a bagofwords CountVectorizer. This will turn each document to be a 1D array, which I think is a good starting point for putting into my clustering algorithms. Let's see how it does. \n",
    "\n",
    "The count vectorizer only accepts the Series if the document is represented as a String, not a tokenized list. This string form also represents each row as a document. That's ultimately what I need to do for my clustering to be effective, because each point needs to represent one sequence altogether, not vectorized individual words.\n",
    "\n",
    "I set the min_df paramater to 5 to only include terms that occur more than 5 times in my Count Vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vectorizing the data with Count Vectorizer\n",
    "bagofwords = CountVectorizer(min_df = 5).fit(string_processed_inbound)\n",
    "inbound_cv = bagofwords.transform(string_processed_inbound)\n",
    "\n",
    "# For visualizing top 10\n",
    "def top10_bagofwords(data, output_name, title):\n",
    "    ''' Taking as input the data and plots the top 10 words based on counts in this text data'''\n",
    "    bagofwords = CountVectorizer()\n",
    "    # Output will be a sparse matrix\n",
    "    inbound = bagofwords.fit_transform(data)\n",
    "    # Inspecting of often contractions and colloquial language is used\n",
    "    word_counts = np.array(np.sum(inbound, axis=0)).reshape((-1,))\n",
    "    words = np.array(bagofwords.get_feature_names_out())\n",
    "    words_df = pd.DataFrame({\"word\":words, \n",
    "                             \"count\":word_counts})\n",
    "    words_rank = words_df.sort_values(by=\"count\", ascending=False)\n",
    "    # words_rank.to_csv('words_rank.csv') # Storing it in a csv so I can inspect and go through it myself\n",
    "    words_rank.head()\n",
    "    # Visualizing top 10 words\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(words_rank['word'][:10], words_rank['count'][:10].astype(str), palette = 'inferno')\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Saving\n",
    "    plt.savefig(f'visualizations/{output_name}.png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "top10_bagofwords(string_processed_inbound, 'initial_frequencies', 'Top 10 Words in Processed Inbound Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mostly use count vectorizer to see top 10 words that occur in a particular dataset and visualize it here.\n",
    "\n",
    "From the visualization above, this tells me most of the customer queries are about phones, particularly iOS and battery fixes. We also see thanks rank quite high, which is a good thing because it might indicate gratitude (which indicates a closing intent for my chatbot). Hi (rank 44) and hey (rank 25) classifies a greeting intent, and it's good to see that they appear a lot of times. Things are looking promising right now, but we wouldn't be able to see the quality until we actually start clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<77175x34110 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1259391 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, ngram_range = (1,3))\n",
    "# Storing tfidf data and transforming them into sparse matrices\n",
    "inbound_tfidf = tfidf.fit_transform(string_processed_inbound)\n",
    "inbound_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained word embeddings\n",
    "\n",
    "Bag of words lose many of the subtleties such as word ordering. This is why I will try these other text vectorization methods. These days we have more effective methods, especially since what I want to encode in these vectors are intent clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GloVe\n",
    "I am going to use multiple word embeddings to vectorize my text in different ways, and then test which one is the best word embedding to use, starting with the Glove word embedding. GloVe is an unsupervised learning algorithm for getting vector representations for words.\n",
    "\n",
    "Gensim constrains pretrained word embeddings and have a special data format where you can basically load it in as a numpy array.\n",
    "\n",
    "DISCLAIMER: I won't be using this one because my clustering algorithms only work when each tweet is one point, and this is a word transformer. I am leaving this part in my notebook as a progress log.\n",
    "\n",
    "Useful sources for this step: \n",
    "* [Guide to word to vec word embeddings](https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92)\n",
    "* Zeugma Docs\n",
    "    * https://pypi.org/project/zeugma/0.41/\n",
    "    * https://github.com/nkthiebaut/zeugma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EmbeddingTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m glove \u001b[38;5;241m=\u001b[39m EmbeddingTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglove\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Applying it to the entire training data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m inbound_glove \u001b[38;5;241m=\u001b[39m string_processed_inbound\u001b[38;5;241m.\u001b[39mprogress_apply(glove\u001b[38;5;241m.\u001b[39mtransform)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EmbeddingTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "glove = EmbeddingTransformer('glove')\n",
    "# Applying it to the entire training data\n",
    "inbound_glove = string_processed_inbound.progress_apply(glove.transform)\n",
    "# Preview shapes\n",
    "inbound_glove.iloc[0].shape, inbound_glove.iloc[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, gloVe transforms individual sentences as multiple word vectors. We need an algorithm that transforms the entire sentence to one vector, so that it represents one point in space.\n",
    "\n",
    "It's interesting, though, to play with this around conceptually even if we won't use it. We can check the cosine similarity between the first and second sentence should give you similarities across words in the sequence, which is interesting because it works when they are of different length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(inbound_glove.iloc[0], inbound_glove.iloc[1])\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for intepretation, the cosine similarity could be 0 if the two vectors are perpendicular. And it seems that the similarity matrix takes the shape of the longer matrix that it compares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Doc2Vec\n",
    "Since this is the main embedding method I will use for my pipeline, I display how I capitalized this embedding in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hugging Face\n",
    "This is a startup that does a lot with NLP. I explore their encoders.\n",
    "\n",
    "BERT wouldn't really be a good option because a large part of that was trained with Wikipedia data.\n",
    "\n",
    "I am not sure what doc2vec is trained on, I think my results will be better if I find a Twitter based word embedding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fast-text \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we cluster, let's make scaled versions of our dataset first, which would be good for distance-based clustering methods. In general, these vectors shouldn't really need scaling, but it may help for computational purposes. I only do this for my count vectorized and tfidf vectorized data, not ones with the more meaningful word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<77175x4893 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 768941 stored elements in Compressed Sparse Row format>,\n",
       " <77175x34110 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1259391 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the data we have so far, they are stored in CSR compressed format\n",
    "inbound_cv, inbound_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<77175x4893 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 768941 stored elements in Compressed Sparse Row format>,\n",
       " <77175x4893 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 768941 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting and transforming to create standard scaled versions of my data\n",
    "inbound_cv_ma = MaxAbsScaler().fit_transform(inbound_cv)\n",
    "inbound_tfidf_ma = MaxAbsScaler().fit_transform(inbound_cv)\n",
    "\n",
    "inbound_cv_ma, inbound_tfidf_ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练考虑：**因为我将在项目的下一部分训练神经网络，所以我的目标是拥有大约10个意图（通过EDA，取决于数据中自然意图的实际数量）。对于这10个意图中的每一个，我想为每个意图提供大约1000个示例。我选择这个特定的数字是因为我希望每个意图的例子分布均匀，这样我就不会出现类不平衡，而且我的神经网络可以相对较好地对这十个类进行分类。\n",
    "\n",
    "\n",
    "考虑到这一点，让探索开始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我将尝试在我的数据上使用聚类方法和主题建模来提取主要主题并手动标记这些聚类。\n",
    "\n",
    "如果我的数据都在同一类型的客户服务领域，我会取得更大的成功，而且我很小心地确保推特-苹果的数据是这样的。这样，我在下一个笔记本电脑中的模型将捕捉到意图分类的细微差别。一般来说，机器人会擅长用它所训练的语言谈论话题。\n",
    "\n",
    "我知道，使用集群，您不能期望您的模型以预先集群的方式对数据进行集群。这是一个整体算法。我希望他们能神奇地将意图轻松地聚集在一起，然而现在可能就那么容易了！我们拭目以待。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>1. K Means</color>\n",
    "我对单词向量进行聚类的第一种方法是K-Means，它往往在Blob上表现良好。\n",
    "\n",
    "缺点是它非常慢，而且很难选择K的值——我甚至不知道数据中有多少意图。这就是为什么我从K的较大跳跃开始，以获得哪一个表现最好的更高层次的想法，然后我深入研究，最终决定什么K最适合在我的数据集中找到最佳意图数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. 我的TFIDF和计数矢量化数据的K-Means\n",
    "首先，我对TFIDF和计数矢量化数据进行了聚类。老实说，我不会真的期望它能带来好的结果，所以我不会花很多精力在这两个方面进行实际的聚类。但值得一试，以证明一种较老且次优的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('inbound_cv_ma', <77175x4893 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 768941 stored elements in Compressed Sparse Row format>)\n",
      "1 ('inbound_tfidf_ma', <77175x4893 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 768941 stored elements in Compressed Sparse Row format>)\n"
     ]
    }
   ],
   "source": [
    "# Vectorized data\n",
    "vectorized_data = {'inbound_cv_ma': inbound_cv_ma, 'inbound_tfidf_ma': inbound_tfidf_ma}\n",
    "# Briefly showing the contents of i and j\n",
    "for i,j in enumerate(vectorized_data.items()): print(i,j);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我正在对这里的所有数据运行我的整个K-Means。我正在对n_clusters进行超参数优化。第一个进度条是它如何处理数据集，第二个是它完成了所有n_clusters。\n",
    "\n",
    "在缩放之前，我花了三个小时在10到100的10次迭代中对这两种数据类型应用K-Means。幸运的是，在我攀登之后，它训练得更快了。\n",
    "\n",
    "我使用Python的序列化包Pickle将结果存储在这个单元格下面，这样我就不必再运行它了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014228343963623047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 32,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614bfdfaab844045a270609c79735759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016389131546020508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 32,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03015a4c676f473a96d733ec5c9bc2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently fitting inbound_cv_ma with 10 clusters... Please wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009977102279663086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 32,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8b76cbb55943f28fa29be008afd934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently fitting inbound_tfidf_ma with 10 clusters... Please wait\n",
      "CPU times: user 3min 27s, sys: 1min 1s, total: 4min 29s\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# My grand dictionaries that will store all my results\n",
    "wcss_grand = {}\n",
    "labels_grand = {}\n",
    "silhouette_scores_grand = {}\n",
    "# n_clusters = [10,20,30,40,50,60,70,80,90,100]\n",
    "n_clusters = [10]\n",
    "\n",
    "# Iterating through all the differently embedded data\n",
    "for i,j in tqdm(enumerate(vectorized_data.items())): \n",
    "    name = j[0] # Here j[0] is the name of the dataset\n",
    "    dataset = j[1] # And j[1] is the actual data\n",
    "    \n",
    "    # I store my metrics at these following lists\n",
    "    wcss = []\n",
    "    labels = []\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    # Looping through values of k\n",
    "    for k in tqdm(n_clusters):    \n",
    "        print(f'Currently fitting {name} with {k} clusters... Please wait')\n",
    "        \n",
    "        # Initializing with k-means++ ensures that you get don’t fall into the random initialization trap.\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state = 10)\n",
    "        kmeans.fit(dataset)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "        \n",
    "        # Getting the silhouette score\n",
    "        labels.append(kmeans.labels_)\n",
    "        silhouette_scores.append(silhouette_score(dataset, kmeans.labels_))\n",
    "        \n",
    "        # Saving the models\n",
    "        filename = f'models/kmeans/{name}-{k}neighbors.sav'\n",
    "        joblib.dump(kmeans, filename)\n",
    "        \n",
    "    # Updating grand dictionary\n",
    "    wcss_grand[name + '_wcss'] = wcss\n",
    "    labels_grand[name + '_labels'] = labels\n",
    "    silhouette_scores_grand[name + '_silhouettes'] = silhouette_scores\n",
    "\n",
    "# Saving all my results\n",
    "with open('objects/wcss_grand.pkl', 'wb') as handle:\n",
    "    pickle.dump(wcss_grand, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('objects/labels_grand.pkl', 'wb') as handle:\n",
    "    pickle.dump(labels_grand, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('objects/silhouette_scores_grand.pkl', 'wb') as handle:\n",
    "    pickle.dump(silhouette_scores_grand, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading back in the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing it into objects I can use in this notebook\n",
    "\n",
    "with open('objects/wcss_grand.pkl', 'rb') as handle:\n",
    "    wcss_grand = pickle.load(handle)\n",
    "with open('objects/labels_grand.pkl','rb') as handle:\n",
    "    labels_grand = pickle.load(handle)\n",
    "with open('objects/silhouette_scores_grand.pkl','rb') as handle:\n",
    "    silhouette_scores_grand = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寻找最佳K-Means模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我正在画一个肘部图，看看是否有一个清晰的肘部，希望我能找到，但可能性不大。\n",
    "\n",
    "我首先对**count个矢量化的**数据进行处理，然后对**tfidf**矢量化的数据进行处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Elbow Plot count vectorized\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m101\u001b[39m, \u001b[38;5;241m10\u001b[39m), wcss_grand[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minbound_cv_ma_wcss\u001b[39m\u001b[38;5;124m'\u001b[39m], color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmagenta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElbow Method (Count Vectorized)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of clusters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/matplotlib/pyplot.py:2728\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2726\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2729\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2730\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1662\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elbow Plot count vectorized\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(10, 101, 10), wcss_grand['inbound_cv_ma_wcss'], color = 'magenta')\n",
    "plt.title('Elbow Method (Count Vectorized)')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# Elbow Plot tfidf\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(10, 101, 10), wcss_grand['inbound_tfidf_ma_wcss'], color = 'magenta')\n",
    "plt.title('Elbow Method (TFIDF)')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# Silouette Plot count vectorized\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(10, 101, 10), silhouette_scores_grand['inbound_cv_ma_silhouettes'], color = 'red')\n",
    "plt.title('Silhouette Method (Count Vectorized)')\n",
    "plt.xlabel('Silhouette Score')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# Silouette Plot tfidf\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(10, 101, 10), silhouette_scores_grand['inbound_tfidf_ma_silhouettes'], color = 'red')\n",
    "plt.title('Silhouette Method (TFIDF)')\n",
    "plt.xlabel('Silhouette Score')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到这些图在TFIDF和计数矢量化数据之间并没有太大变化，这进一步说明了我上面的说法，即它们并不是最有用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用t-SNE可视化我的集群"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我尝试不同的颜色贴图并选择一个，这样更容易区分簇。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available sequential colormaps:\n",
    "\n",
    "```['viridis', 'plasma', 'inferno', 'magma', 'cividis']```\n",
    "\n",
    "```['Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',\n",
    "            'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
    "            'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']```\n",
    "\n",
    "Available qualitative colormaps:\n",
    "```['Pastel1', 'Pastel2', 'Paired', 'Accent',\n",
    "                        'Dark2', 'Set1', 'Set2', 'Set3',\n",
    "                        'tab10', 'tab20', 'tab20b', 'tab20c']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current data\n",
    "inbound_cv_ma.shape, inbound_tfidf_ma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE是一个概率模型，所以这需要一些时间，特别是因为我们有大约80k行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Instantiate t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=1, n_jobs=-1)\n",
    "\n",
    "# Fit t-SNE\n",
    "inbound_cv_ma_tsne = tsne.fit_transform(inbound_cv_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting my visualization for each of my n_neighbors with my count vectorized data\n",
    "\n",
    "for k in range(10,101,10):\n",
    "    # Getting the right K-Means cluster labels.\n",
    "    labels = joblib.load(f'models/kmeans/inbound_cv_ma-{str(k)}neighbors.sav').labels_\n",
    "    \n",
    "    # Visualize high-dimensional data\n",
    "    plt.figure(figsize=(13,12))\n",
    "    plt.scatter(inbound_cv_ma_tsne[:,0], inbound_cv_ma_tsne[:,1], s=20, c = labels, cmap = 'magma')\n",
    "    plt.title(f'2-D t-SNE Representation of my Count Vectorized Inbound data with {k} Clusters')\n",
    "    plt.xlabel('t-SNE dimension 1')\n",
    "    plt.ylabel('t-SNE dimension 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一开始我以为我真的看不到任何星团！但请记住，我有这么多数据点，所以我必须把这些集群做得很大。很酷的绘图，尽管我们的高维数据的2D表示不会非常准确，但我们还远远没有看到清晰的聚类！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我不希望它有太大的不同，但让我们看看我的TFIDF数据的相同图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Instantiate t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=1, n_jobs=-1)\n",
    "\n",
    "# Fit t-SNE\n",
    "inbound_tfidf_ma_tsne = tsne.fit_transform(inbound_tfidf_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting my visualization for each of my n_neighbors with my tfidf data\n",
    "\n",
    "for k in range(10,101,10):\n",
    "    # Getting the right K-Means cluster labels.\n",
    "    labels = joblib.load(f'models/kmeans/inbound_tfidf_ma-{str(k)}neighbors.sav').labels_\n",
    "    \n",
    "    # Visualize high-dimensional data\n",
    "    plt.figure(figsize=(13,12))\n",
    "    plt.scatter(inbound_tfidf_ma_tsne[:,0], inbound_tfidf_ma_tsne[:,1], s=20, c = labels, cmap = 'magma')\n",
    "    plt.title(f'2-D t-SNE Representation of my TFIDF Inbound data with {k} Clusters')\n",
    "    plt.xlabel('t-SNE dimension 1')\n",
    "    plt.ylabel('t-SNE dimension 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "果不其然，这些看起来真的很像计数矢量化集群！让我们继续讨论单词嵌入集群，我认为这更有趣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. K-Means for my Doc2Vec data\n",
    "\n",
    "请注意，我没有故意缩放d2v数据，因为我不想扭曲预训练模型创建的距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized data\n",
    "vectorized_data = {'inbound_cv_d2v': inbound_d2v}\n",
    "# Briefly showing the contents of i and j\n",
    "for i,j in enumerate(vectorized_data.items()): print(i,j);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My d2v dictionaries that will store all my results\n",
    "wcss_d2v = {}\n",
    "labels_d2v = {}\n",
    "silhouette_scores_d2v = {}\n",
    "n_clusters = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "# Iterating through all the differently embedded data\n",
    "for i,j in tqdm(enumerate(vectorized_data.items())): \n",
    "    name = j[0] # Here j[0] is the name of the dataset\n",
    "    dataset = j[1] # And j[1] is the actual data\n",
    "    \n",
    "    # I store my metrics at these following lists\n",
    "    wcss = []\n",
    "    labels = []\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    # Looping through values of k\n",
    "    for k in tqdm(n_clusters):    \n",
    "        print(f'Currently fitting {name} with {k} clusters... Please wait')\n",
    "        \n",
    "        # Initializing with k-means++ ensures that you get don’t fall into the random initialization trap.\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state = 10)\n",
    "        kmeans.fit(dataset)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "        \n",
    "        # Getting the silhouette score\n",
    "        labels.append(kmeans.labels_)\n",
    "        silhouette_scores.append(silhouette_score(dataset, kmeans.labels_))\n",
    "        \n",
    "        # Saving the models\n",
    "        filename = f'models/kmeans/{name}-{k}neighbors.sav'\n",
    "        joblib.dump(kmeans, filename)\n",
    "        \n",
    "    # Updating d2v dictionary\n",
    "    wcss_d2v[name + '_wcss'] = wcss\n",
    "    labels_d2v[name + '_labels'] = labels\n",
    "    silhouette_scores_d2v[name + '_silhouettes'] = silhouette_scores\n",
    "\n",
    "# Saving all my results, now with a d2v tag\n",
    "with open('objects/wcss_d2v.pkl', 'wb') as handle:\n",
    "    pickle.dump(wcss_d2v, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('objects/labels_d2v.pkl', 'wb') as handle:\n",
    "    pickle.dump(labels_d2v, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('objects/silhouette_scores_d2v.pkl', 'wb') as handle:\n",
    "    pickle.dump(silhouette_scores_d2v, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading back in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing it into objects I can use in this notebook\n",
    "\n",
    "with open('objects/wcss_d2v.pkl', 'rb') as handle:\n",
    "    wcss_d2v = pickle.load(handle)\n",
    "with open('objects/labels_d2v.pkl','rb') as handle:\n",
    "    labels_d2v = pickle.load(handle)\n",
    "with open('objects/silhouette_scores_d2v.pkl','rb') as handle:\n",
    "    silhouette_scores_d2v = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Plot d2v\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(10, 101, 10), wcss_d2v['inbound_cv_d2v_wcss'], color = 'magenta')\n",
    "plt.title('Elbow Method (Doc2Vec)')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# Silouette Plot d2v\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(10, 101, 10), silhouette_scores_d2v['inbound_cv_d2v_silhouettes'], color = 'red')\n",
    "plt.title('Silhouette Method (Doc2Vec)')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we see that we have a slightly higher silhouette score which isn't negative now. It looks like K = 20 would be the best in this case as it has the highest silhouette score and there is sort of an elbow in the elbow plot, definitely more than at 80 clusters where it seems to be completely smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Instantiate t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=1, n_jobs=-1)\n",
    "\n",
    "# Fit t-SNE\n",
    "inbound_d2v_tsne = tsne.fit_transform(inbound_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting my visualization for each of my n_neighbors, now with Doc2Vec embedded data\n",
    "\n",
    "for k in range(10,101,10):\n",
    "    # Getting the right K-Means cluster labels.\n",
    "    labels = joblib.load(f'models/kmeans/inbound_cv_d2v-{str(k)}neighbors.sav').labels_\n",
    "    \n",
    "    # Visualize high-dimensional data\n",
    "    plt.figure(figsize=(13,12))\n",
    "    plt.scatter(inbound_d2v_tsne[:,0], inbound_d2v_tsne[:,1], s=20, c = labels, cmap = 'magma')\n",
    "    plt.title(f'2-D t-SNE Representation of my Doc2Vec Inbound data with {k} Clusters')\n",
    "    plt.xlabel('t-SNE dimension 1')\n",
    "    plt.ylabel('t-SNE dimension 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于t-SNE图很难判断，因此，我将在后面的部分通过实际查看标签来评估它是如何聚集的！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>2. LDA (Latent Dirichlet Allocation) </color>\n",
    "我的第二种聚类方法是LDA主题建模。它基本上会获取您的数据并将其拆分为多个主题。我的目标仍然是集群，但通过这种方法，我希望获得更有用、更独特的主题。\n",
    "\n",
    "\n",
    "Useful articles:\n",
    "* https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "* https://medium.com/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05\n",
    "\n",
    "还有一些新的、基于深度学习的方法，称为LDA2Vec，也可能很有兴趣探索。\n",
    "\n",
    "然而，由于比例的变化，我将把这一步作为未来的一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "# Load the LDA model from sk-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    " \n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "# Tweak the two parameters below\n",
    "number_topics = 5\n",
    "number_words = 10\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(count_data)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "LDAvis_data_filepath = os.path.join('./ldavis_prepared_'+str(number_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, count_data, count_vectorizer)\n",
    "with open(LDAvis_data_filepath, 'w') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath) as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './ldavis_prepared_'+ str(number_topics) +'.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出于时间限制的考虑，我决定不使用DBScan，因为它们将获得类似于K-Means的聚类结果。我也可以使用高斯混合模型或Heirarchical聚类来实现这个聚类结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 发现并可视化集群之间的意图差异"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我把我所有的模型都保存在这个名为文件夹的目录中的一个文件夹中。我所要做的就是为该模型选择一个超参数设置，并可视化这些聚类中的单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_inbound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我认为查看集群中的前10个单词非常有用，可以很好地了解集群中的意图！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using scattertext from the spaCy universe for EDA\n",
    "This [kernel](https://www.kaggle.com/psbots/customer-support-meets-spacy-universehttps://www.kaggle.com/psbots/customer-support-meets-spacy-universe) showed me what spaCy's scattertext tool is capable of doing! So I wanted to do it myself as well to hopefully get useful insights.\n",
    "\n",
    "正如文档中所说，散点文本是“一种在中小型语料库中找到区别术语的工具，并用不重叠的术语标签在性感的交互式散点图中呈现它们。”\n",
    "\n",
    "这对于比较我在以下笔记本中的意图集群也非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls models/kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = joblib.load(f'models/kmeans/inbound_cv_d2v-10neighbors.sav').labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattertext for cluster evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(love['Text'], category_col = \n",
    "                             parsed_col = 'parsed').build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category='British_Airways',\n",
    "#           category_name='British Airways',\n",
    "#           not_category_name='American Airlines',\n",
    "#           width_in_pixels=600,\n",
    "#           minimum_term_frequency=10,\n",
    "#           term_significance = st.LogOddsRatioUninformativeDirichletPrior(),\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this cell to load the interactive scattertext visualisation\n",
    "# filename = \"americanAir-vs-britishAirways.html\"\n",
    "# open(filename, 'wb').write(html.encode('utf-8'))\n",
    "# IFrame(src=filename, width = 800, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using scattertext from the spaCy universe for EDA\n",
    "This [kernel](https://www.kaggle.com/psbots/customer-support-meets-spacy-universehttps://www.kaggle.com/psbots/customer-support-meets-spacy-universe) showed me what spaCy's scattertext tool is capable of doing! So I wanted to do it myself as well to hopefully get useful insights.\n",
    "\n",
    "As said in the docs, scatter-text is \"a tool for finding distinguishing terms in small-to-medium-sized corpora, and presenting them in a sexy, interactive scatter plot with non-overlapping term labels.\"\n",
    "\n",
    "This will be very useful for comparing my intent clusters in the following notebook as well.\n",
    "\n",
    "corpus = st.CorpusFromParsedDocuments(processed_inbound,\n",
    "                             parsed_col = 'parsed').build()\n",
    "\n",
    "# html = st.produce_scattertext_explorer(corpus,\n",
    "#           category='British_Airways',\n",
    "#           category_name='British Airways',\n",
    "#           not_category_name='American Airlines',\n",
    "#           width_in_pixels=600,\n",
    "#           minimum_term_frequency=10,\n",
    "#           term_significance = st.LogOddsRatioUninformativeDirichletPrior(),\n",
    "#           )\n",
    "\n",
    "# uncomment this cell to load the interactive scattertext visualisation\n",
    "# filename = \"americanAir-vs-britishAirways.html\"\n",
    "# open(filename, 'wb').write(html.encode('utf-8'))\n",
    "# IFrame(src=filename, width = 800, height=700)def top10_bagofwords(data):\n",
    "    ''' Taking as input the data and plots the top 10 words based on counts in this text data'''\n",
    "    bagofwords = CountVectorizer()\n",
    "    inbound = bagofwords.fit_transform(data)\n",
    "    inbound # Output will be a sparse matrix\n",
    "    # Inspecting of often contractions and colloquial language is used\n",
    "    word_counts = np.array(np.sum(inbound, axis=0)).reshape((-1,))\n",
    "    words = np.array(bagofwords.get_feature_names())\n",
    "    words_df = pd.DataFrame({\"word\":words, \n",
    "                             \"count\":word_counts})\n",
    "    words_rank = words_df.sort_values(by=\"count\", ascending=False)\n",
    "    # words_rank.to_csv('words_rank.csv') # Storing it in a csv so I can inspect and go through it myself\n",
    "    words_rank.head()\n",
    "    # Visualizing top 10 words\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.barplot(words_rank['word'][:10], words_rank['count'][:10].astype(str), color = 'salmon')\n",
    "    plt.title('Top 10 Most Common Words in My Data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Approach: Heuristic Intent Distribution Exploration\n",
    "I need to get an idea of how much true intents are inside my Twitter data. Doing it by keyword might prove to be a good baseline way to do this. I build off this idea, and do a heuristic clustering of my intents by trying to minimize intent intersections. I try to boil down with this method to have the most distinct and _mutually exclusive_ sets of intents so that Eve bot will be able to be trained to distinguish these intents.\n",
    "\n",
    "I was inspired by seeing other solutions, such as the implementation by cortex, where they made a \"semantic fingerprint\" per intent. Obviously, the details of that are not shared, but it was enough for me to try to think of my own solution. Initially, I was going to stem off the clustering and try to manually pick out 1000 examples manually, but that is just not a smart idea and is extremely labor intensive.\n",
    "\n",
    "This notebook is my way of getting my training data for intent classificaition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(f'pandas: {pd.__version__}')\n",
    "import numpy as np\n",
    "print(f'numpy: {np.__version__}')\n",
    "# Visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "# Making my visualizations pretty\n",
    "sns.set_style('whitegrid')\n",
    "# Combination exploration\n",
    "import itertools\n",
    "import yaml\n",
    "\n",
    "# Loading back processed data\n",
    "processed = pd.read_pickle('objects/processed.pkl')\n",
    "print(f'\\ninbound:\\n{processed.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Keyword Search EDA\n",
    "Using this as a tool to look at Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search by keywords (single keyword filter)\n",
    "keyword = 'info'\n",
    "\n",
    "# Seeing what the processed Tweets look like\n",
    "filt = [(i,j) for i,j in enumerate(processed['Processed Inbound']) if keyword in j]\n",
    "filtered = processed.iloc[[i[0] for i in filt]]\n",
    "print(f'{len(filtered)} Tweets contain the keyword {keyword}')\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*filtered['Real Inbound']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Intents:\n",
    "\n",
    "<img src=\"visualizations/intent_list.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这个单元格代表了我寻找意图的旅程。最后，下面的一切都是为了通知这个字典的选择，并随后创建我的训练数据。当我意识到我也可以将其与命名实体识别相结合时，它大大减少了。\n",
    "\n",
    "你会注意到它并没有包含所有内容，这是因为有些意图不在我的训练数据中——它们必须手动创建。这方面的例子是问候语：这个训练数据不会只包含只有“嗨”的推文，它们几乎总是包含多个意图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc Intents: I find the keywords that is associated with intent and search based on these keywords\n",
    "\n",
    "# Version 1 - Initial Mockup: Making a dictionary to store intents and the predefined responses\n",
    "\n",
    "intents = {\"Greeting\": [\"Hi there!\",\"Hello\"], \n",
    " \"Closing\":\"Thanks for talking\", \n",
    " \"Promotion\":\"\",\n",
    "           \"Scenarios\": {'Last payment': \"\", \"Account details\":\"\", \n",
    "                         \"Account confirmation\": \"\"},\n",
    "    \"Location\": \"\"}\n",
    "\n",
    "# Version 2 - Just for showing progress\n",
    "intents = {'greeting': ['hi', 'hello', 'hey','yo'], 'app': ['app', 'application'],\n",
    "          'iphone': ['iphone', 'i phone'], 'icloud': ['icloud', 'i cloud'],\n",
    "          'ios': ['io'], 'battery': ['battery'], 'watch': ['watch'], 'mac': \n",
    "           ['mac', 'macbook', 'laptop', 'computer'], 'update': ['update'],\n",
    "          'troubleshooting': ['problem', 'trouble', 'error'],\n",
    "          'settings': ['settings', 'setting'], 'music': ['music', 'song', 'playlist'],\n",
    "          'payment': ['credit','card','payment','pay'], 'bug':['bug'], 'watch': ['tv', 'show'],\n",
    "          'network': ['internet','connection','network']}\n",
    "\n",
    "# Intents that require all words within it to be contained in the list (alternative filtering method)\n",
    "intents_all = {'ios update': ['io', 'update'], 'app update': ['app','update']}\n",
    "\n",
    "# Version 3\n",
    "intents = {'update': ['update'], 'battery': ['battery', 'power'], 'forgot_password':['password','account','login'],\n",
    "          'repair':['repair','fix','broken'],  \n",
    "           'payment': ['credit','card','payment','pay']}\n",
    "\n",
    "# Storing it to YAML file\n",
    "with open('objects/intents.yml', 'w') as outfile:\n",
    "    yaml.dump(intents, outfile, default_flow_style=False)\n",
    "\n",
    "print('INTENTS FOR KEYWORD EDA BELOW:\\n ------------------------')\n",
    "for i in intents.items():\n",
    "    print('Intent: {} \\n   Keywords: {}'.format(i[0], \" + \".join(i[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions I made. Will be very useful for the intent exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three different ways to filter out Tweets based on Keywords\n",
    "# 1.\n",
    "def get_key_tweets(series, keywords):\n",
    "    ''' Takes as input the list of keywords and outputs the Tweets that contains at least\n",
    "    one of these keywords '''\n",
    "    keyword_tweets = []\n",
    "    for tweet in series:\n",
    "        # Want to check if keyword is in tweets\n",
    "        for keyword in keywords:\n",
    "            if keyword in tweet:\n",
    "                keyword_tweets.append(tweet)\n",
    "    return keyword_tweets\n",
    "\n",
    "# 2. Making a function that filters to Tweets that needs to have ALL the keywords\n",
    "def all_key_tweets(series, keywords):\n",
    "    ''' Takes as input the list of keywords and outputs the Tweets have all the keywords'''\n",
    "    keyword_absent_tweets = []\n",
    "    for tweet in series:\n",
    "        # Want to check if keyword is not in tweets\n",
    "        if all(item in tweet for item in keywords):\n",
    "            keyword_absent_tweets.append(tweet)\n",
    "    return keyword_absent_tweets\n",
    "\n",
    "# 3. Making a function that filters to tweets that DONT contain any of the keywords\n",
    "def key_absent_tweets(series, keywords):\n",
    "    ''' Takes as input the list of keywords and outputs the Tweets that don't contain any\n",
    "    of these keywords '''\n",
    "    keyword_absent_tweets = []\n",
    "    for tweet in series:\n",
    "        # Want to check if keyword is not in tweets\n",
    "        if not any(item in tweet for item in keywords):\n",
    "            keyword_absent_tweets.append(tweet)\n",
    "    return keyword_absent_tweets\n",
    "\n",
    "# Getting a list of all my keywords so far\n",
    "all_keywords = []\n",
    "for keywords in intents.values():\n",
    "    for keyword in keywords:\n",
    "        all_keywords.append(keyword)      \n",
    "        \n",
    "\n",
    "def only_key_tweets(series, keywords):\n",
    "    ''' Uses the all_keywords '''\n",
    "    kept = list()\n",
    "    for tweet in series:\n",
    "        # Check\n",
    "        if all(elem in tweet for elem in keywords):\n",
    "            kept.append(tweet)\n",
    "    return pd.Series(kept)\n",
    "        \n",
    "def to_set(l):\n",
    "    ''' In order to make the Tweets a set to check for intersections, we need\n",
    "    to make them immutable by making it a tuple because sets only accept immutable\n",
    "    elements '''\n",
    "    return set([tuple(row) for row in l])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function above to visualize the distribution of intents in my dataset\n",
    "\n",
    "intent_lengths = [len(get_key_tweets(processed['Processed Inbound'], intents[intent])) for intent in intents.keys()]\n",
    "keyword = pd.DataFrame({'intents': list(intents.keys()), 'intent_lengths': intent_lengths}).sort_values('intent_lengths', ascending = False)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.bar(keyword['intents'], keyword['intent_lengths'], color = '#00acee')\n",
    "plt.title('Distribution of Intents Using Keyword Searching')\n",
    "plt.xlabel('Intent')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of Tweets with the Intent Keywords')\n",
    "plt.show()\n",
    "\n",
    "# Proportions visualization\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.bar(keyword['intents'], keyword['intent_lengths'] * 100 / 75879, color = '#00acee')\n",
    "plt.title('Distribution of Intents Using Keyword Searching')\n",
    "plt.xlabel('Intent')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Percentage of Tweets with the Intent Keywords')\n",
    "# Saving\n",
    "plt.savefig('visualizations/intent_distribution_keyword.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing precise numeric counts\n",
    "keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这里来看，我们似乎没有足够的钱让最后两个意图获得1000，但这没关系，因为我可以稍后复制它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我还为至少包含一个问题的推文数量做了一个替代过滤器。在这次探索中，我发现在75879个总数中，27373个至少包含一个问号（36.1%）。\n",
    "\n",
    "### 组合勘探\n",
    "\n",
    "在这里，我想看看搜索到的不同类别之间有多少推文重叠。如果意图之间有太多的重叠，这意味着我们可以为特定的推文标记两个意图。我认为这仍然有效，尽管这意味着我们需要看看如何回应双重意图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing all the thresholds for min amount of combination appearances\n",
    "thres = [500,10,5,5]\n",
    "\n",
    "# Intent Tweets have all the keys, and as the value contains all the tweets that contain that key, as a set\n",
    "intent_tweets = {}\n",
    "for key in intents.keys():\n",
    "    intent_tweets[key] = to_set(get_key_tweets(processed['Processed Inbound'],intents[key]))\n",
    "\n",
    "# Iterating through all pairs, and getting how many Tweets intersect between the pair\n",
    "keyword_overlaps = {}\n",
    "\n",
    "# COMBINATIONS OF 2\n",
    "\n",
    "# Each i returns a tuple containing a pair of length r, which in this case is 2\n",
    "for i in list(itertools.combinations(list(intents.keys()),2)):\n",
    "    a = to_set(intent_tweets[i[0]])\n",
    "    b = to_set(intent_tweets[i[1]])\n",
    "    # Inserting pair to dictionary\n",
    "    keyword_overlaps[f\"{i[0]} + {i[1]}\"] = len(a.intersection(b))\n",
    "\n",
    "# Filtering to just the significant ones, which I define as greater than 100\n",
    "combs = []\n",
    "counts = []\n",
    "for i in keyword_overlaps.items():\n",
    "    if i[1] > thres[0]:\n",
    "        combs.append(i[0])\n",
    "        counts.append(i[1])\n",
    "\n",
    "# Visualizing as well\n",
    "v = pd.DataFrame({'Combination': combs, \"Counts\": counts}).sort_values('Counts', ascending = False)\n",
    "plt.figure(figsize=(9,6))\n",
    "sns.barplot(x = v['Combination'], y = v['Counts'], palette = 'magma')\n",
    "plt.title(f'Combinations of 2 Keywords (At Least {thres[0]} Occurances)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# COMBINATIONS OF 3\n",
    "keyword_overlaps = {}\n",
    "\n",
    "try:\n",
    "    # Each i returns a tuple containing a pair of length r, which in this case is 3\n",
    "    for i in list(itertools.combinations(list(intents.keys()),3)):\n",
    "        a = to_set(intent_tweets[i[0]])\n",
    "        b = to_set(intent_tweets[i[1]])\n",
    "        c = to_set(intent_tweets[i[2]])\n",
    "        # Inserting pair to dictionary\n",
    "        keyword_overlaps[f\"{i[0]} + {i[1]} + {i[2]}\"] = len(a.intersection(b).intersection(c))\n",
    "\n",
    "    # Filtering to just the significant ones, which I define as greater than 100\n",
    "    combs = []\n",
    "    counts = []\n",
    "    for i in keyword_overlaps.items():\n",
    "        if i[1] > thres[1]:\n",
    "            combs.append(i[0])\n",
    "            counts.append(i[1])\n",
    "\n",
    "    # Visualizing as well\n",
    "    v = pd.DataFrame({'Combination': combs, \"Counts\": counts}).sort_values('Counts', ascending = False)\n",
    "    plt.figure(figsize=(9,6))\n",
    "    sns.barplot(x = v['Combination'], y = v['Counts'], palette = 'magma')\n",
    "    plt.title(f'Combinations of 3 Keywords (At Least {thres[1]} Occurances)')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "except ValueError as e:\n",
    "    print(f'Not enough 3-combinations (Thres = {thres[1]})')\n",
    "    \n",
    "# COMBINATIONS OF 4\n",
    "keyword_overlaps = {}\n",
    "\n",
    "try:\n",
    "    # Each i returns a tuple containing a pair of length r, which in this case is 4\n",
    "    for i in list(itertools.combinations(list(intents.keys()),4)):\n",
    "        a = to_set(intent_tweets[i[0]])\n",
    "        b = to_set(intent_tweets[i[1]])\n",
    "        c = to_set(intent_tweets[i[2]])\n",
    "        d = to_set(intent_tweets[i[3]])\n",
    "        # Inserting pair to dictionary\n",
    "        keyword_overlaps[f\"{i[0]} + {i[1]} + {i[2]} + {i[3]}\"] = len(a.intersection(b).intersection(c).intersection(d))\n",
    "\n",
    "    # Filtering to just the significant ones, which I define as greater than 10\n",
    "    combs = []\n",
    "    counts = []\n",
    "    for i in keyword_overlaps.items():\n",
    "        if i[1] > thres[2]:\n",
    "            combs.append(i[0])\n",
    "            counts.append(i[1])\n",
    "\n",
    "    # Visualizing as well\n",
    "    v = pd.DataFrame({'Combination': combs, \"Counts\": counts}).sort_values('Counts', ascending = False)\n",
    "    plt.figure(figsize=(9,6))\n",
    "    sns.barplot(x = v['Combination'], y = v['Counts'], palette = 'magma')\n",
    "    plt.title(f'Combinations of 4 Keywords (At Least {thres[2]} Occurances)')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "except ValueError as e:\n",
    "    print(f'Not enough 4-combinations (Thres = {thres[2]})')\n",
    "\n",
    "# GROUPS OF 5\n",
    "keyword_overlaps = {}\n",
    "\n",
    "try:\n",
    "    # Each i returns a tuple containing a pair of length r, which in this case is 5\n",
    "    for i in list(itertools.combinations(list(intents.keys()),5)):\n",
    "        a = to_set(intent_tweets[i[0]])\n",
    "        b = to_set(intent_tweets[i[1]])\n",
    "        c = to_set(intent_tweets[i[2]])\n",
    "        d = to_set(intent_tweets[i[3]])\n",
    "        e = to_set(intent_tweets[i[4]])\n",
    "        # Inserting pair to dictionary\n",
    "        keyword_overlaps[f\"{i[0]} + {i[1]} + {i[2]} + {i[3]} + {i[4]}\"] = len(a.intersection(b).intersection(c).intersection(d).intersection(e))\n",
    "\n",
    "    # Filtering to just the significant ones, which I define as greater than 5\n",
    "    combs = []\n",
    "    counts = []\n",
    "    for i in keyword_overlaps.items():\n",
    "        if i[1] > thres[3]:\n",
    "            combs.append(i[0])\n",
    "            counts.append(i[1])\n",
    "\n",
    "    # Visualizing as well\n",
    "    v = pd.DataFrame({'Combination': combs, \"Counts\": counts}).sort_values('Counts', ascending = False)\n",
    "    plt.figure(figsize=(9,6))\n",
    "    sns.barplot(x = v['Combination'], y = v['Counts'], palette = 'magma')\n",
    "    plt.title(f'Combinations of 5 Keywords (At Least {thres[3]} Occurances)')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "except ValueError as e:\n",
    "    print(f'Not enough 5-combinations (Thres = {thres[3]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在4的组合中看到，很明显，客户想问我们什么。出现407次的最高一次是（“手机记录+ios+电池+更新”）-这是客户想要为他们的iphone推荐关于他们的ios的内容，这是关于更新的内容。\n",
    "\n",
    "这里甚至可以看到5的组合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了苹果自己的[@applesupport](https://twitter.com/AppleSupport)，还有什么比看看还有什么意图更好的地方推特页面？\n",
    "\n",
    "* 我们看到，更新通常存在于许多组合中\n",
    "* 大多数意图通常是一个又一个的组合！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，基于相似推文数量的绝对值，我们不会很难为每个意图类别找到1000个训练示例，尤其是更新！将较高的发生率分解为更细微、更独特的类别可能也是一个好主意。此外，我通常想使用超过1000条推文的意图，好消息是大多数意图每条推文都超过1000条。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Cases\n",
    "我想测试一下，可能会有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanted to group iOS update into one intent. \n",
    "# But since ios and update occured a lot other I put them together into one intent group. \n",
    "\n",
    "print('app intents without ios: {}'.format(len(key_absent_tweets(get_key_tweets(processed_inbound, intents['app']), ['io']))))\n",
    "key_absent_tweets(get_key_tweets(processed_inbound, intents['app']), ['io']);\n",
    "\n",
    "# Exploration of combinations and \"purity\" of a cluster\n",
    "print('both ios and update appears: {}'.format(6000))\n",
    "print('just ios: {}'.format(len(get_key_tweets(processed_inbound, intents['ios']))))\n",
    "print('ios but no update: {}'.format(len(get_key_tweets(processed_inbound, intents['ios'])) - 6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我想查找我在启发式搜索中没有考虑的所有推文\n",
    "可能最有用的过滤器是这个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the key absent function\n",
    "key_absent_tweets(processed['Processed Inbound'].iloc, all_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这里，我得到了解释的灵感：\n",
    "* Settings\n",
    "* Apple Music\n",
    "* Phone\n",
    "* Credit card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_key_tweets(processed_inbound, intents_all['ios update'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_key_tweets(processed_inbound, ['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings might not be the best intent to try on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the Tweets with that specific keyword\n",
    "len(get_key_tweets(processed_inbound, intents['greeting'])), 27373/75879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_key_tweets(processed_inbound, intents['app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents['greeting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_inbound.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 捕获的意图\n",
    "（这只是我认为意图的另一个版本-你可以看到这些意图有多个版本，因为这是一个迭代启发式优化过程）-实际上我花了一段时间才找到如何挖掘意图的好指南。\n",
    "\n",
    "1. Greeting\n",
    "2. App recommendations\n",
    "    * Need to tag the actual appication we want\n",
    "    * Need to tag the problem\n",
    "3. Hardware recommendations\n",
    "    * Phone hardware issue\n",
    "    * Battery health\n",
    "6. ICloud photos\n",
    "7. Apple watch\n",
    "8. Software (iOS)/ update bugs\n",
    "9. Statement (not really asking for anything, it is just giving a statement about something) - If possible, I would like to remove these because they are not really that useful to me.\n",
    "    * Opinions\n",
    "    * Complaint\n",
    "    * Thinking about this point further, it might be useful to include question marks in the data because that encodes useful information about whether or not a customer is making a question or not.\n",
    "10. Want to purchase\n",
    "11. Gratitude/Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
